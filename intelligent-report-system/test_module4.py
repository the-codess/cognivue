"""
Test script for Module 4 - Conversational Interface
Run this to validate the module is working correctly
"""
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.absolute()
sys.path.insert(0, str(project_root))

from src.modules.input_processing.processor import InputProcessor
from src.modules.role_context.context_analyzer import RoleContextAnalyzer
from src.modules.insight_generation.generator import InsightGenerator
from src.modules.conversational_interface.manager import ConversationManager
from src.utils.sample_data_generator import SampleDataGenerator
from src.utils.logger import app_logger as logger

def print_section(title):
    """Print a section header"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")

def chat(manager, session_id, query, insights):
    """Simulate a chat interaction"""
    print(f"ðŸ‘¤ User: {query}")
    response = manager.process_message(session_id, query, insights)
    print(f"ðŸ¤– Assistant: {response.response_text}")
    print(f"   [Intent: {response.intent.value} | Confidence: {response.confidence:.0%}]")
    if response.suggested_questions:
        print(f"   ðŸ’¡ Suggestions: {', '.join(response.suggested_questions[:2])}")
    print()
    return response

def test_module4():
    """Test Module 4 - Conversational Interface"""
    
    print_section("MODULE 4: CONVERSATIONAL INTERFACE - TEST SUITE")
    
    # Step 1: Initialize all components
    print_section("Step 1: Initializing Full System (Hybrid LLM + Pattern Matching)")
    
    input_processor = InputProcessor()
    context_analyzer = RoleContextAnalyzer()
    insight_generator = InsightGenerator()
    conversation_manager = ConversationManager(use_llm=True)  # Enable LLM
    generator = SampleDataGenerator()
    
    print("âœ“ InputProcessor initialized")
    print("âœ“ RoleContextAnalyzer initialized")
    print("âœ“ InsightGenerator initialized")
    
    if conversation_manager.use_llm:
        print("âœ“ ConversationManager initialized with LLM support (Ollama)")
        print(f"  Model: {conversation_manager.llm_handler.model_name}")
    else:
        print("âœ“ ConversationManager initialized with pattern matching only")
        print("  Note: Install Ollama for LLM support (see OLLAMA_SETUP.md)")
    
    # Step 2: Generate data and insights
    print_section("Step 2: Generating Insights for Conversation")
    
    print("Processing sales data...")
    sales_file = generator.generate_sales_data(num_rows=300)
    sales_data = input_processor.process_file(sales_file)
    
    print("Generating insights...")
    insights = insight_generator.generate_insights(sales_data)
    
    print(f"âœ“ Processed {sales_data.metadata.row_count} rows")
    print(f"âœ“ Generated {insights.total_count} insights")
    print(f"âœ“ Average confidence: {insights.avg_confidence:.1%}")
    
    # Step 3: Create conversation session
    print_section("Step 3: Starting Conversation Session")
    
    session_id = conversation_manager.create_session(user_role="cfo")
    print(f"âœ“ Session created: {session_id}")
    print("âœ“ Ready for conversation\n")
    
    # Step 4: Test different query types
    print_section("Step 4: Testing Conversational Queries")
    
    print("--- Scenario 1: Getting Started ---")
    chat(conversation_manager, session_id, "Hi, what do you have for me?", insights)
    
    print("--- Scenario 2: Summary Request ---")
    chat(conversation_manager, session_id, "Give me a summary of the key insights", insights)
    
    print("--- Scenario 3: Clarification Question ---")
    chat(conversation_manager, session_id, "Why is quantity increasing?", insights)
    
    print("--- Scenario 4: Drill Down ---")
    chat(conversation_manager, session_id, "Tell me more details about the trends", insights)
    
    print("--- Scenario 5: Comparison ---")
    chat(conversation_manager, session_id, "Compare the performance across regions", insights)
    
    print("--- Scenario 6: Recommendations ---")
    chat(conversation_manager, session_id, "What should I do about these findings?", insights)
    
    # Step 5: Test intent classification
    print_section("Step 5: Intent Classification Testing")
    
    test_queries = [
        "Show me a summary",
        "Why did revenue decline?",
        "Compare Q1 to Q2",
        "What should we do next?",
        "Tell me more about anomalies",
        "What if we increase budget by 20%?",
        "Show me a bar chart"
    ]
    
    processor = conversation_manager.query_processor
    
    print("Intent Classification Results:\n")
    for query in test_queries:
        classification = processor.classify_intent(query)
        print(f"Query: '{query}'")
        print(f"  Intent: {classification.intent.value}")
        print(f"  Confidence: {classification.confidence:.0%}")
        if classification.keywords:
            print(f"  Keywords: {', '.join(classification.keywords)}")
        print()
    
    # Step 6: Test conversation history
    print_section("Step 6: Conversation History")
    
    history = conversation_manager.get_conversation_history(session_id)
    print(f"Conversation turns: {len(history)}\n")
    
    for i, turn in enumerate(history[:3], 1):
        print(f"Turn {i}:")
        print(f"  User: {turn['user'][:60]}...")
        print(f"  Intent: {turn['intent']}")
        print()
    
    # Step 7: Multi-turn conversation simulation
    print_section("Step 7: Multi-Turn Conversation Flow")
    
    print("Simulating a complete conversation flow...\n")
    
    new_session = conversation_manager.create_session(user_role="analyst")
    
    conversation_flow = [
        "Hello, I'm new here. What can you help me with?",
        "Show me the main insights",
        "Explain the first one",
        "What data supports this conclusion?",
        "What should I investigate further?"
    ]
    
    for query in conversation_flow:
        chat(conversation_manager, new_session, query, insights)
    
    # Step 8: Test without insights
    print_section("Step 8: Handling Edge Cases")
    
    print("--- Test: No insights available ---")
    empty_session = conversation_manager.create_session()
    response = chat(conversation_manager, empty_session, "Give me a summary", None)
    
    # Step 9: Summary
    print_section("Test Summary")
    
    print("Module 4 - Conversational Interface\n")
    print("âœ“ Conversation Manager: WORKING")
    print("âœ“ Query Processor: WORKING")
    print("âœ“ Intent Classification: WORKING")
    print("âœ“ Session Management: WORKING")
    print("âœ“ Multi-turn Conversations: WORKING")
    print("âœ“ Context Tracking: WORKING")
    print("âœ“ Response Generation: WORKING")
    print("âœ“ Edge Case Handling: WORKING")
    
    print("\n" + "="*80)
    print("MODULE 4 TESTING COMPLETED SUCCESSFULLY")
    print("="*80)
    
    print("\nKey Capabilities Demonstrated:")
    print("1. Natural language query understanding (no LLM required)")
    print("2. Intent classification with pattern matching")
    print("3. Context-aware responses")
    print("4. Multi-turn conversation management")
    print("5. Suggested follow-up questions")
    print("6. Insight referencing and explanation")
    
    print("\nConversation Statistics:")
    print(f"  Total sessions: {len(conversation_manager.active_sessions)}")
    print(f"  Queries processed: {len(history) + len(conversation_flow)}")
    print(f"  Intents supported: 9")
    
    print("\nNext Steps:")
    print("1. Test conversational interface with real users")
    print("2. Review conversation flows and responses")
    print("3. Proceed to Module 5 (Feedback & Learning)")
    
    return True

if __name__ == "__main__":
    try:
        test_module4()
    except Exception as e:
        logger.error(f"Test failed with error: {str(e)}")
        print(f"\nâœ— TEST FAILED: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)